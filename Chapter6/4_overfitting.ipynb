{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4_overfitting.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNr39e4h7oeLHe1Na9dMF8S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/msjun23/Deep-Learning-from-Scratch/blob/main/Chapter6/4_overfitting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcPv--MxmXnR"
      },
      "source": [
        "# 오버피팅\r\n",
        "\r\n",
        "**오버피팅**(overfitting)이란 신경망이 훈련 데이터에 지나치게 적응되어 그 외의 데이터에는 제대로 대응하지 못하는 상태를 말한다. 오버피팅은 주로 다음과 같은 경우에 일어난다.\r\n",
        "- 매개변수가 많고 표현력이 높은 모델\r\n",
        "- 훈련 데이터가 적음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cWkiKUQmS_e"
      },
      "source": [
        "# 임의로 오버피팅을 발생시키기\r\n",
        "import os\r\n",
        "import sys\r\n",
        "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from mnist import load_mnist\r\n",
        "from common.util import smooth_curve\r\n",
        "from common.multi_layer_net import MultiLayerNet\r\n",
        "from common.optimizer import *\r\n",
        "\r\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\r\n",
        "\r\n",
        "# 오버피팅을 재현하기 위해 학습 데이터 수를 줄임\r\n",
        "x_train = x_train[:300]\r\n",
        "t_train = t_train[:300]\r\n",
        "\r\n",
        "network = MultiLayerNet(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100], output_size=10)\r\n",
        "optimizer = SGD(lr=0.01)    # 학습률이 0.01인 SGD로 매개변수 갱신\r\n",
        "\r\n",
        "max_epochs = 201\r\n",
        "train_size = x_train.shape[0]\r\n",
        "batch_size = 100\r\n",
        "\r\n",
        "train_loss_list = []\r\n",
        "train_acc_list = []\r\n",
        "test_acc_list = []\r\n",
        "\r\n",
        "iter_per_epoch = max(train_size / batch_size, 1)\r\n",
        "epoch_cnt = 0\r\n",
        "\r\n",
        "for i in range(10000):\r\n",
        "  batch_mask = np.random.choice(train_size, batch_size)\r\n",
        "  x_batch = x_train[batch_mask]\r\n",
        "  t_batch = t_train[batch_mask]\r\n",
        "\r\n",
        "  grads = network.gradient(x_batch, t_batch)\r\n",
        "  optimizer.update(network.params, grads)\r\n",
        "\r\n",
        "  if i % iter_per_epoch == 0:\r\n",
        "    train_acc = network.accuracy(x_train, t_train)\r\n",
        "    test_acc = network.accuracy(x_test, t_test)\r\n",
        "    train_acc_list.append(train_acc)\r\n",
        "    test_acc_list.append(test_acc)\r\n",
        "\r\n",
        "    epoch_cnt += 1\r\n",
        "    if epoch_cnt >= max_epochs:\r\n",
        "      break"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ji63DKbbuf8t"
      },
      "source": [
        "학습 그래프를 그려보면 오버피팅이 일어난 것을 확인할 수 있다.(교재 p.217)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6nmwqZeuqLL"
      },
      "source": [
        "# 드롭아웃\r\n",
        "\r\n",
        "신경망 모델이 복잡해지면 가중치 감소만으로는 대응하기 어려워 진다. 이럴 때는 흔히 드롭아웃(dropout)이라는 기법을 이용한다.\r\n",
        "\r\n",
        "드롭아웃은 임의로 뉴런을 삭제하면서 학습하는 방법이다. 훈련 때 뉴런을 무작위로 골라 삭제한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxwLj-e-o0s9"
      },
      "source": [
        "# 드롭아웃 구현\r\n",
        "class Dropout:\r\n",
        "  def __init__(self, dropout_ratio=0.5):\r\n",
        "    self.dropout_ratio = dropout_ratio\r\n",
        "    self.mask = None\r\n",
        "\r\n",
        "  def forward(self, x, train_flg=True):\r\n",
        "    if train_flg:\r\n",
        "      self.mask = np.random.rand(*x.shape) > self.dropout_ratio\r\n",
        "      return x * self.mask\r\n",
        "    else:\r\n",
        "      return x * (1.0 - self.dropout_ratio)\r\n",
        "\r\n",
        "  def backward(self, dout):\r\n",
        "    return dout * self.mask"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ql8ogjYRwTKK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}