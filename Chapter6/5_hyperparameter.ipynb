{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5_hyperparameter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPN2SL8mnouYsJZaaAJWWCB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/msjun23/Deep-Learning-from-Scratch/blob/main/Chapter6/5_hyperparameter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XovG0uqxUmV"
      },
      "source": [
        "# 하이퍼파라미터\r\n",
        "\r\n",
        "하이퍼파라미터란 학습을 통해 값을 얻는게 아닌 사용자가 정하는 값들이다. 예를 들어 각 층의 뉴런 수, 배치 크기, 매개변수 갱신 시의 학습률, 가중치 감소 등이 있다.\r\n",
        "\r\n",
        "훈련(train)을 진행하고 시험(test)을 하기 전에 하이퍼파라미터를 조정하기 위해 하이퍼파라미터 전용 확인 데이터가 필요하다. 이를 일반적으로 **검증 데이터**(validation data)라고 한다.\r\n",
        "\r\n",
        "> - 훈련 데이터 : 매개변수 학습\r\n",
        "> - 검증 데이터 : 하이퍼파라미터 성능 평가\r\n",
        "> - 시험 데이터 : 신경망의 범용 성능 평가"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xImjV5Mzy10W"
      },
      "source": [
        "```\r\n",
        "# 데이터 나누기\r\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist()\r\n",
        "\r\n",
        "# 훈련 데이터를 뒤섞는다.\r\n",
        "x_train, t_train = shuffle_dataset(x_train, t_train)\r\n",
        "\r\n",
        "# 20%를 검증 데이터로 분할\r\n",
        "validation_rate = 0.20\r\n",
        "validation_num = int(x_train.shape[0] * validation_rate)\r\n",
        "\r\n",
        "x_val = x_train[:validation_num]\r\n",
        "t_val = t_train[:validation_num]\r\n",
        "x_train = x_train[validation_num:]\r\n",
        "t_train = t_tarin[validation_num:]\r\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRpWsN1lzEf2"
      },
      "source": [
        "하이퍼파라미터를 최적화 하는 것은 \"최적 값\"이 존재하는 범위를 조금씩 줄여가는 것이다.\r\n",
        "\r\n",
        "> 신경망의 하이퍼파라미터 최적화에서는 무작위로 샘플링해 탐색하는 편이 더 좋은 결과를 낸다.\r\n",
        "\r\n",
        "실제로도 0.001에서 1000 사이와 같이 '10의 거듭제곱'단위로 범위를 지정한다. 이를 **로그 스케일**(log scale)로 지정한다고 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qk0e1Ra_zpQ9"
      },
      "source": [
        "0. 하이퍼파라미터 값의 범위를 설정한다.\r\n",
        "1. 설정된 범위에서 하이퍼파라미터의 값을 무작위로 추출한다.\r\n",
        "2. 1단계에서 샘플링한 하이퍼파라미터 값을 사용하여 학습하고, 검증 데이터로 정확도를 평가한다.(단, 에폭을 작게 설정한다.)\r\n",
        "3. 1단계와 2단계를 특정 횟수(100회 등) 반복하여, 그 정확도의 결과를 보고 하이퍼파라미터의 범위를 좁힌다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USeE0qVny5BT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}