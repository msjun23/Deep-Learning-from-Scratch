{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_batch_normalization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN4GOUEfKqiyhYeRB9KCw2c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/msjun23/Deep-Learning-from-Scratch/blob/main/Chapter6/3_batch_normalization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMQPwHYngEVq"
      },
      "source": [
        "# 배치 정규화\r\n",
        "\r\n",
        "**배치 정규화**(Batch Normalization)의 효과는 아래와 같다.\r\n",
        "- 학습 속도가 빨라진다.\r\n",
        "- 초깃값의 의존도가 낮아진다.\r\n",
        "- 오버피팅을 억제한다.\r\n",
        "\r\n",
        "배치 정규화는 학습 시 미니배치를 단위로 정규화를 한다. 데이터 분포의 평균이 0, 분산이 1이 되도록 정규화 한다. 수식은 다음과 같다. $\\mu$는 평균, $\\sigma$는 분산을 의미한다.\r\n",
        "$$\\mu_B\\leftarrow\\frac{1}{m}\\sum_{i=1}^mx_i\r\n",
        "\\\\\r\n",
        "\\sigma_B^2\\leftarrow\\frac{1}{m}\\sum_{i=1}^m(x_i-\\mu_B)^2\r\n",
        "\\\\\r\n",
        "\\hat{x_i}\\leftarrow\\frac{x_i-\\mu_B}{\\sqrt{\\sigma_B^2+\\epsilon}}$$\r\n",
        "\r\n",
        "또 배치 정규화 계층마다 이 정규화된 데이터에 고유한 확대(scale)와 이동(shift) 변환을 수행한다. 수식은 아래와 같다.\r\n",
        "$$y_i\\leftarrow\\gamma\\hat{x_i}+\\beta$$\r\n",
        "\r\n",
        "여기서 $\\gamma$는 확대, $\\beta$는 이동을 담당한다. 초깃값은 각각 1, 0으로 시작하여 학습을 진행하면서 적합한 값으로 조정한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_362WbG4ee2n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}