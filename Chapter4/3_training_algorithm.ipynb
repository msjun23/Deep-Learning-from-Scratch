{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "3_training_algorithm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMy0Hs+EIZzQ0YD37LkiVY0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/msjun23/Deep-Learning-from-Scratch/blob/main/Chapter4/3_training_algorithm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSrxdVCWsnQS"
      },
      "source": [
        "# 신경망 학습\r\n",
        "\r\n",
        "- 전제 : 훈련 데이터에 적응하도록 가중치와 편향을 조정하는 과정을 '학습'이라 한다.\r\n",
        "- 1단계 - 미니배치 : 훈련 데이터 중 일부를 무작위로 가져온다. 이렇게 선별한 데이터를 미내배치라 하며, 그 미니배치의 손실 함수값을 줄이는 것이 목표이다.\r\n",
        "- 2단계 - 기울기 산출 : 손실 함수의 값을 줄이기 위해 각 가중치 매개변수의 기울기를 구한다. 기울기는 손실 함수의 값을 가장 작게 하는 방향을 제시한다.\r\n",
        "- 3단계 - 매개변수 갱신 : 기중치 매개변수를 기울기 방향으로 조금씩 갱신한다.\r\n",
        "- 4단계 - 반복\r\n",
        "\r\n",
        "경사 하강법으로 매개변수를 갱신하며, 데이터를 미니배치로 무작위로 선정하는 이런 방식을 **확률적 경사 하강법**(stochastic gradient descent)라 한다. 대부분의 딥러닝 프레임워크는 **SGD**라는 함수로 이 기능을 구현한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neJYf_jJsKqo"
      },
      "source": [
        "# TwoLayerNet 구현\r\n",
        "import sys, os\r\n",
        "sys.path.append(os.pardir)\r\n",
        "from functions import *\r\n",
        "from gradient import numerical_gradient\r\n",
        "\r\n",
        "class TwoLayerNet:\r\n",
        "  def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\r\n",
        "    # 가중치 초기화\r\n",
        "    self.params = {}\r\n",
        "    self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\r\n",
        "    self.params['b1'] = np.zeros(hidden_size)\r\n",
        "    self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\r\n",
        "    self.params['b2'] = np.zeros(output_size)\r\n",
        "\r\n",
        "  def predict(self, x):\r\n",
        "    W1, W2 = self.params['W1'], self.params['W2']\r\n",
        "    b1, b2 = self.params['b1'], self.params['b2']\r\n",
        "\r\n",
        "    a1 = np.dot(x, W1) + b1\r\n",
        "    z1 = sigmoid(a1)\r\n",
        "    a2 = np.dot(z1, W2) + b2\r\n",
        "    y = softmax(a2)\r\n",
        "\r\n",
        "    return y\r\n",
        "\r\n",
        "  # x : 입력 데이터, t : 정답 레이블\r\n",
        "  def loss(self, x, t):\r\n",
        "    y = self.predict(x)\r\n",
        "\r\n",
        "    return cross_entropy_error(y, t)\r\n",
        "\r\n",
        "  def accuracy(self, x, t):\r\n",
        "    y = self.predict(x)\r\n",
        "    y = np.argmax(y, axis=1)    # 예측 결과가 가장 높은 클래스의 인덱스 반환\r\n",
        "    t = np,argmax(t, axis=1)    # 정답 레이블의 인덱스 반환\r\n",
        "\r\n",
        "    accuracy = np.sum(y == t) / float(x.shape[0])\r\n",
        "    return accuracy\r\n",
        "\r\n",
        "  # x : 입력 데이터, y : 정답 레이블\r\n",
        "  def numerical_gradient(self, x, t):\r\n",
        "    loss_W = lambda W: self.loss(x, t)\r\n",
        "\r\n",
        "    grads = {}\r\n",
        "    grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\r\n",
        "    grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\r\n",
        "    grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\r\n",
        "    grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\r\n",
        "\r\n",
        "    return grads"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VoL-9z3yCUv",
        "outputId": "6cba1409-644e-4808-8b36-98fefe45e728"
      },
      "source": [
        "# 가중치, 편향 출력\r\n",
        "net = TwoLayerNet(input_size=784, hidden_size=100, output_size=10)\r\n",
        "print(net.params['W1'].shape)\r\n",
        "print(net.params['b1'].shape)\r\n",
        "print(net.params['W2'].shape)\r\n",
        "print(net.params['b2'].shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(784, 100)\n",
            "(100,)\n",
            "(100, 10)\n",
            "(10,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DWxPjpXycXM"
      },
      "source": [
        "# 더미 입력 데이터(100장 분량)\r\n",
        "x = np.random.randn(100, 784)\r\n",
        "y = net.predict(x)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNbPjqKly-se",
        "outputId": "7e6ac43f-d7ca-437d-bdb3-0b0de5e272cd"
      },
      "source": [
        "# 더미 입력 데이터, 정답 레이블\r\n",
        "x = np.random.randn(100, 784)\r\n",
        "t = np.random.randn(100, 10)\r\n",
        "\r\n",
        "grads = net.numerical_gradient(x, t)\r\n",
        "\r\n",
        "print(grads['W1'].shape)\r\n",
        "print(grads['b1'].shape)\r\n",
        "print(grads['W2'].shape)\r\n",
        "print(grads['b2'].shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(784, 100)\n",
            "(100,)\n",
            "(100, 10)\n",
            "(10,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubKuDXN03k6D"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        },
        "id": "DzZ3p0lJzpQ4",
        "outputId": "fb9955e0-93d3-411d-cfc6-aaa6cb9f1f2f"
      },
      "source": [
        "# 미니배치 학습 구현하기\r\n",
        "from mnist import load_mnist\r\n",
        "\r\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\r\n",
        "\r\n",
        "train_loss_list = []\r\n",
        "\r\n",
        "# 하이퍼파라미터\r\n",
        "iters_num = 10000   # 반복 횟수\r\n",
        "train_size = x_train.shape[0]\r\n",
        "batch_size = 100    # 미니배치 크기\r\n",
        "learning_rate = 0.1\r\n",
        "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\r\n",
        "\r\n",
        "for i in range(iters_num):\r\n",
        "  # 미니배치 획득\r\n",
        "  batch_mask = np.random.choice(train_size, batch_size)\r\n",
        "  x_batch = x_train[batch_mask]\r\n",
        "  t_batch = t_train[batch_mask]\r\n",
        "\r\n",
        "  # 기울기 계산\r\n",
        "  grad = network.numerical_gradient(x_batch, t_batch)\r\n",
        "\r\n",
        "  # 매개변수 갱신\r\n",
        "  for key in ('W1', 'b1', 'W2', 'b2'):\r\n",
        "    network.params[key] -= learning_rate * grad[key]\r\n",
        "\r\n",
        "  # 학습 경과 기록\r\n",
        "  loss = network.loss(x_batch, t_batch)\r\n",
        "  train_loss_list.append(loss)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading train-images-idx3-ubyte.gz ... \n",
            "Done\n",
            "Downloading train-labels-idx1-ubyte.gz ... \n",
            "Done\n",
            "Downloading t10k-images-idx3-ubyte.gz ... \n",
            "Done\n",
            "Downloading t10k-labels-idx1-ubyte.gz ... \n",
            "Done\n",
            "Converting train-images-idx3-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Converting train-labels-idx1-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Converting t10k-images-idx3-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Converting t10k-labels-idx1-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Creating pickle file ...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-fba78b0fe223>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0;31m# 기울기 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0;31m# 매개변수 갱신\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-e159c3dc15c4>\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gradient.py\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[0;34m(f, x)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_val\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mfxh2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# f(x-h)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfxh1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfxh2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-e159c3dc15c4>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(W)\u001b[0m\n\u001b[1;32m     41\u001b[0m   \u001b[0;31m# x : 입력 데이터, y : 정답 레이블\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mloss_W\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-e159c3dc15c4>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0;31m# x : 입력 데이터, t : 정답 레이블\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcross_entropy_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-e159c3dc15c4>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0ma2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1xZFIGrEcJd"
      },
      "source": [
        "(오래 걸림)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECcrYYm85d18"
      },
      "source": [
        "# 미니배치 학습 구현하기\r\n",
        "from mnist import load_mnist\r\n",
        "\r\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\r\n",
        "print(x_train.shape, t_train.shape)\r\n",
        "print(x_test.shape, t_test.shape)\r\n",
        "\r\n",
        "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\r\n",
        "\r\n",
        "# 하이퍼파라미터\r\n",
        "iters_num = 10000   # 반복 횟수\r\n",
        "train_size = x_train.shape[0]\r\n",
        "batch_size = 100    # 미니배치 크기\r\n",
        "learning_rate = 0.1\r\n",
        "\r\n",
        "train_loss_list = []\r\n",
        "train_acc_list = []\r\n",
        "test_acc_list = []\r\n",
        "\r\n",
        "# 1에폭 당 반복 수\r\n",
        "iter_per_epoch = max(train_size / batch_size, 1)    # 60,000 / 100 = 600\r\n",
        "\r\n",
        "for i in range(iters_num):\r\n",
        "  # 미니배치 획득\r\n",
        "  batch_mask = np.random.choice(train_size, batch_size)\r\n",
        "  x_batch = x_train[batch_mask]\r\n",
        "  t_batch = t_train[batch_mask]\r\n",
        "\r\n",
        "  # 기울기 계산\r\n",
        "  # grad = network.numerical_gradient(x_batch, t_batch)\r\n",
        "  grad = network.numerical_gradient(x_batch, t_batch)\r\n",
        "\r\n",
        "  # 매개변수 갱신\r\n",
        "  for key in ('W1', 'b1', 'W2', 'b2'):\r\n",
        "    network.params[key] -= learning_rate * grad[key]\r\n",
        "\r\n",
        "  # 학습 경과 기록\r\n",
        "  loss = network.loss(x_batch, t_batch)\r\n",
        "  train_loss_list.append(loss)\r\n",
        "\r\n",
        "  # 1에폭 당 정확도 계산\r\n",
        "  if i % iter_per_epoch == 0:\r\n",
        "    train_acc = network.accuracy(x_train, t_train)\r\n",
        "    test_acc = network.accuracy(x_test, t_test)\r\n",
        "    train_acc_list.append(train_acc)\r\n",
        "    test_acc_list.append(test_acc)\r\n",
        "    print('train acc, test acc : ' + str(train_acc) + ', ' + str(test_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2qnnicbJcbJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}