{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMeWpZ41NJCvlmgDoGKKXmc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/msjun23/Deep-Learning-from-Scratch/blob/main/Chapter3/MNIST_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqS1tXEC2E60"
      },
      "source": [
        "#손글씨 숫자 인식\r\n",
        "이미 학습된 매개변수를 사용하여 학습 과정은 생략하고, 추론 과정만 구현해본다. 이 추론 과정을 신경망의 **순전파**(forward propagation)라고 한다.\r\n",
        "\r\n",
        "> 신경망을 이용해 문제를 해결하는 것은 두 단계로 나뉜다. 먼저 훈련 데이터(학습 데이터)를 사용해 가중치 매개변수를 학습하고, 추론 단계에서는 앞서 학습한 매개변수를 사용하여 입력 데이터를 분류한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8DcW4FM2mR-"
      },
      "source": [
        "#MNIST 데이터 셋\r\n",
        "\r\n",
        "딥러닝을 한번이라도 공부해 봤다면 들어봤을 손글씨 숫자 이미지 집합이다. 아주 유명한 데이터셋으로 여러 논문 등에서 실험용 데이터로 많이 쓰인다.\r\n",
        "\r\n",
        "0 부터 9 까지의 숫자 이미지로, 훈련(train) 데이터가 60,000장, 시험(test) 데이터가 10,000장 준비되어 있다. 각 이미지 데이터는 $28\\times28$ 크기의 그레이스캐일(grayscale, 1차원) 이미지이며, 각 픽셀은 0 에서 255 까지의 값을 취한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HE0QfJb11vAE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e87a2884-9eb6-48fa-f098-adbf29d87a68"
      },
      "source": [
        "import sys, os\r\n",
        "sys.path.append(os.pardir)    # 부모 디렉터리의 파일을 가져올 수 있도록 설정\r\n",
        "from mnist import load_mnist\r\n",
        "\r\n",
        "# 처음 한 번은 몇 분 정도 걸립니다.\r\n",
        "(x_train, y_train), (x_test, y_test) = load_mnist(flatten=True, normalize=False)\r\n",
        "\r\n",
        "# 각 데이터의 형상 출력\r\n",
        "print(x_train.shape)\r\n",
        "print(y_train.shape)\r\n",
        "print(x_test.shape)\r\n",
        "print(y_test.shape)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(60000,)\n",
            "(10000, 784)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVFe-XJyBnSc"
      },
      "source": [
        "load_mnist라는 함수를 사용해서 MNIST 데이터를 (훈련 이미지, 훈련 레이블), (시험 이미지, 시험 레이블) 형식으로 불러온다. 인수로는 아래 세 가지를 설정할 수 있다. 모두 bool형으로 True로 설정하면 아래와 같다.\r\n",
        "\r\n",
        "- normalize : 입력 이미지의 픽셀값을 0.0 ~ 1.0 사이의 값으로 정규화한다.\r\n",
        "- flatten : 입력 이미지를 1차원 배열로 만든다. $1\\times28\\times28$의 3차원 배열을 784개의 원소를 가진 1차원 배열로 변환하여 저장한다.\r\n",
        "- one_hot_label : 원-핫 인코딩이란, 정답 레이블 중 정답을 뜻하는 원소만 1이고 나머지는 모두 0인 배열이다. 정답 레이블의 형태를 원-핫 인코딩으로 저장한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoLhi8fglu93",
        "outputId": "145ca34d-bc35-4187-a5e4-3020485bee6d"
      },
      "source": [
        "# 첫 번째 훈련 이미지를 화면에 표시한다.\r\n",
        "import sys, os\r\n",
        "sys.path.append(os.pardir)\r\n",
        "import numpy as np\r\n",
        "from mnist import load_mnist\r\n",
        "from PIL import Image\r\n",
        "\r\n",
        "def img_show(img):\r\n",
        "  pil_img = Image.fromarray(np.uint8(img))\r\n",
        "  pil_img.show()\r\n",
        "\r\n",
        "(x_train, y_train), (x_test, y_test) = load_mnist(flatten=True, normalize=False)\r\n",
        "\r\n",
        "img = x_train[0]\r\n",
        "label = y_train[0]\r\n",
        "print(label)\r\n",
        "\r\n",
        "print(img.shape)          # flatten=True : (784,) 형태의 1차원 배열\r\n",
        "img = img.reshape(28, 28) # 원래 이미지의 모양으로 변형 (1*28*28)\r\n",
        "print(img.shape)          # (28, 28)\r\n",
        "\r\n",
        "img_show(img)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "(784,)\n",
            "(28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZeCzqcGNptB"
      },
      "source": [
        "이미지를 표시하기 위해 넘파이로 표시된 이미지 데이터를 PIL용 객체로 변환해야 하며, 이 변환은 Image.fromarray()가 수행한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlaiodsZQEPx"
      },
      "source": [
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wI4We35FQJgb"
      },
      "source": [
        "#신경망 추론 정리\r\n",
        "\r\n",
        "MNIST 데이터셋을 가지고 추론을 수행하는 신경망을 구현할 차례이다. 입력 이미지의 크기가 $1\\times28\\times28$ 이므로 입력층 뉴런을 784개, 0 부터 9까지의 숫자를 분류해야 하기 때문에 출력층의 뉴런은 10개로 한다.\r\n",
        "\r\n",
        "은닉층은 총 두개로, 첫 번째 은닉층에는 50개의 뉴런을, 두 번째 은닉층에는 100개의 뉴런을 배치한다. 이 수는 임의로 정한 값이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnKlxGCSXAEP"
      },
      "source": [
        "# sigmoid\r\n",
        "def sigmoid(x):\r\n",
        "  return 1 / (1 + np.exp(-x))\r\n",
        "\r\n",
        "# softmax\r\n",
        "def softmax(a):\r\n",
        "  c = np.max(a)\r\n",
        "  exp_a = np.exp(a - c)\r\n",
        "  sum_exp_a = np.sum(exp_a)\r\n",
        "  y = exp_a / sum_exp_a\r\n",
        "\r\n",
        "  return y"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKNBCGPYJGJZ"
      },
      "source": [
        "# 함수 정의\r\n",
        "import pickle\r\n",
        "\r\n",
        "def get_data():\r\n",
        "  (x_train, y_train), (x_test, y_test) = load_mnist(normalize=True, flatten=True, one_hot_label=False)\r\n",
        "  return x_test, y_test\r\n",
        "\r\n",
        "def init_network():\r\n",
        "  with open('sample_weight.pkl', 'rb') as f:\r\n",
        "    network = pickle.load(f)\r\n",
        "\r\n",
        "  return network\r\n",
        "\r\n",
        "def predict(network, x):\r\n",
        "  W1, W2, W3 = network['W1'], network['W2'], network['W3']\r\n",
        "  b1, b2, b3 = network['b1'], network['b2'], network['b3']\r\n",
        "\r\n",
        "  a1 = np.dot(x, W1) + b1\r\n",
        "  z1 = sigmoid(a1)\r\n",
        "  a2 = np.dot(z1, W2) + b2\r\n",
        "  z2 = sigmoid(a2)\r\n",
        "  a3 = np.dot(z2, W3) + b3\r\n",
        "  y = softmax(a3)\r\n",
        "\r\n",
        "  return y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4u5QJV2qS2Ae",
        "outputId": "f24390fc-26c6-4bdb-f380-9edc2d59894f"
      },
      "source": [
        "# 세 함수를 이용해 신경망에 의한 추론을 수행, 정확도(accuracy - 분류가 얼마나 올바른가) 평가\r\n",
        "x_test, y_test = get_data()\r\n",
        "network = init_network()\r\n",
        "\r\n",
        "accuracy_cnt = 0\r\n",
        "for i in range(len(x_test)):     # 10,000\r\n",
        "  y = predict(network, x_test[i])\r\n",
        "  p = np.argmax(y)    # 확률이 가장 높은 원소의 인덱스를 얻는다. \r\n",
        "  if p == y_test[i]:\r\n",
        "    accuracy_cnt += 1\r\n",
        "\r\n",
        "print('Accuracy: ' + str(float(accuracy_cnt) / len(x_test)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8chnH3hbfsl"
      },
      "source": [
        "0. 가장 먼저 MNIST 데이터셋을 얻고 네트워크를 생성한다.\r\n",
        "1. for문을 돌며 x_test에 저장된 이미지를 한 장씩 꺼내 predict()함수로 분류한다.\r\n",
        "2. 각 레이블의 확률이 반환되면, 이 배열에서 값이 가장 큰 원소의 인덱스를 구한다. 이것이 곧 예측 결과이다.\r\n",
        "3. 예측한 답변과 정답 레이블을 비교하여 맞힌 숫자(accuracy_cnt)를 세고, 전체 이미지 숫자로 나눠 정확도를 구한다.\r\n",
        "\r\n",
        "해당 예제에서 load_mnist 함수의 인수인 normalize를 True로 설정했다. 0 ~ 255 범위인 각 픽셀을 0.0 ~ 1.0 사이의 범위로 변환했다. 이처럼 데이터를 특정 범위로 변환하는 것을 **정규화**(normalization)라 하고, 신경망의 입력 데이터에 특정 변환을 가하는 것을 **전처리**(pre-processing)라 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVi0Rr1ocz0t"
      },
      "source": [
        "#배치 처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tG9EWukhUQTm",
        "outputId": "21961784-e8d5-497d-8afc-e924ac9527b7"
      },
      "source": [
        "x, _ = get_data()\r\n",
        "network = init_network()\r\n",
        "W1, W2, W3 = network['W1'], network['W2'], network['W3']\r\n",
        "\r\n",
        "print(x.shape)\r\n",
        "print(x[0].shape)\r\n",
        "print(W1.shape)\r\n",
        "print(W2.shape)\r\n",
        "print(W3.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 784)\n",
            "(784,)\n",
            "(784, 50)\n",
            "(50, 100)\n",
            "(100, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVfFph66fIiF"
      },
      "source": [
        "위 결과에서 다차원 배열의 대응하는 차원의 원소 수가 일치함을 확인할 수 있다.\r\n",
        "\r\n",
        "- X(784, ) - W1(784, 50) - W2(50, 100) - W3(100, 10) -> Y(10,)\r\n",
        "> 이는 이미지 데이터를 1장만 입력했을 때의 처리 흐름이다.\r\n",
        "\r\n",
        "이미지 여러 장을 한꺼번에 입력하는 경우를 생각해보자. 가령 이미지 100개를 묶어 predict() 함수에 한 번에 넘기면 아래와 같다.\r\n",
        "\r\n",
        "- X(100, 784) - W1(784, 50) - W2(50, 100) - W3(100, 10) -> Y(100, 10)\r\n",
        "> 100장 분량의 입력 데이터의 결과가 한 번에 출력됨을 나타낸다. x[0]와 y[0]에는 0번째 이미지와 그 추론 결과가, x[1]과 y[1]에는 1번째 이미지와 그 추론 결과가 저장되는 식이다.\r\n",
        "\r\n",
        "이처럼 하나로 묶은 입력 데이터를 **배치**(batch)라고 한다.\r\n",
        "\r\n",
        "배치 처리는 컴퓨터로 계산할 때 큰 이점을 준다. 그 이유는 아래와 같이 두가지가 있다.\r\n",
        "\r\n",
        "1. 수치 계산 라이브러리는 대부분이 큰 배열을 효율적으로 처리할 수 있도록 최적화 되어있다.\r\n",
        "2. 데이터 전송이 병목으로 작용하는 경우가 자주 있는데, 배치 처리를 함으로써 버스에 주는 부하를 줄일 수 있다.(느린 I/O를 통해 데이터를 읽는 횟수가 줄고, 빠른 CPU나 GPU로 순수 계산을 수행하는 비율이 높아진다.)\r\n",
        "\r\n",
        "즉, 컴퓨터에서는 **큰 배열을 한꺼번에 계산**하는 것이 분할된 작은 배열을 여러 번 계산하는 것보다 빠르다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFzHfdEQde-J",
        "outputId": "3c8546a7-2b91-4df2-e148-33be51d7bbb9"
      },
      "source": [
        "# 배치 처리 적용\r\n",
        "x_test, y_test = get_data()\r\n",
        "network = init_network()\r\n",
        "\r\n",
        "batch_size = 100    # 배치 크기\r\n",
        "accuracy_cnt = 0\r\n",
        "\r\n",
        "for i in range(0, len(x_test), batch_size):\r\n",
        "  x_batch = x_test[i: i + batch_size]\r\n",
        "  y_batch = predict(network, x_batch)\r\n",
        "  p = np.argmax(y_batch, axis=1)\r\n",
        "  accuracy_cnt += np.sum(p == y_test[i: i + batch_size])\r\n",
        "\r\n",
        "print('Accuracy: ' + str(float(accuracy_cnt) / len(x)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydFH9mvIqFpU"
      },
      "source": [
        "np.argmax() 함수를 사용하여 최댓값의 인덱스를 가져온다. 이때 axis=1 이라는 인수를 추가한 것에 주의한다. 이는 $100\\times10$의 배열 중 1번째 차원을 구성하는 각 원소에서 (1번째 차원을 축으로)최댓값의 인덱스를 찾도록 한 것이다.(0번째 차원이 가장 처음 차원이다.) 여기에 대해서는 아래의 예시를 보면 이해가 빠를 것이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klXPxNYkp9X6",
        "outputId": "41971ca6-2410-4846-9477-9132a03a9bd8"
      },
      "source": [
        "x = np.array([[0.1, 0.8, 0.1], [0.3, 0.1, 0.6], [0.2, 0.5, 0.3], [0.8, 0.1, 0.1]])\r\n",
        "y = np.argmax(x, axis=1)\r\n",
        "print(y)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 2 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EpLObhwrXk4"
      },
      "source": [
        "마지막으로 배치 단위로 분류한 결과를 실제 답과 비교한다. 넘파이 배열끼리 비교하여 True / False로 구성된 bool 배열을 만들고, 이 결과에서 True의 수를 센다. 이 처리 과정은 아래 예식에서 확인할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIZLRvk1rHAj",
        "outputId": "dee874ee-c2c0-49be-ec9c-201224b6e3fb"
      },
      "source": [
        "y = np.array([1, 2, 1, 0])\r\n",
        "t = np.array([1, 2, 0, 0])\r\n",
        "print(y == t)\r\n",
        "print(np.sum(y == t))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ True  True False  True]\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aU8FzqCQr1Gj"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    }
  ]
}